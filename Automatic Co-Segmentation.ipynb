{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1. Start by installing the Personalised Segment Anything Model from Hugging face"
      ],
      "metadata": {
        "id": "CWWKSC6zbtgZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tjO71hTi3f8V"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "from transformers import AutoProcessor, SamModel\n",
        "# from transformers import PerSamModel\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
        "# model = PerSamModel.from_pretrained(\"facebook/sam-vit-huge\")\n",
        "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Necessary python libraries"
      ],
      "metadata": {
        "id": "xPrf9sW7cG1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMww_o3o2h46"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torchvision.transforms.functional import resize, to_pil_image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from transformers import AutoProcessor, SamModel\n",
        "# from transformers import PerSamModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. You can try mounting your google drive where additional models can be downloaded and imported directly into the collab"
      ],
      "metadata": {
        "id": "kzgkIkZMcbVO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYluFa3CpUw_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is where helper fucntions were created for further simplification of the code"
      ],
      "metadata": {
        "id": "S_LixYy7c5dK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUebVEEXut89"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.cluster import KMeans\n",
        "from huggingface_hub import hf_hub_download\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import resize, to_pil_image\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# Function to load images from a directory\n",
        "def load_images_from_directory(directory):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img = Image.open(os.path.join(directory, filename)).convert(\"RGB\")\n",
        "            if img is not None:\n",
        "                images.append((filename, img))\n",
        "    return images\n",
        "\n",
        "# Function to extract features from an image using spatial average\n",
        "def get_image_feature(ref_image):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Step 1: Image features encoding\n",
        "    pixel_values = processor(images=ref_image, return_tensors=\"pt\").pixel_values\n",
        "    with torch.no_grad():\n",
        "        ref_feat = model.get_image_embeddings(pixel_values.to(device))\n",
        "        ref_feat = ref_feat.squeeze().permute(1, 2, 0)\n",
        "\n",
        "    # Compute the mean across the height and width dimensions\n",
        "    spatial_average = ref_feat.mean(dim=(0, 1))\n",
        "\n",
        "    # Reshape to (1, 1, C)\n",
        "    spatial_average = spatial_average.view(1, 1, -1)\n",
        "\n",
        "    return spatial_average\n",
        "\n",
        "# Function to count the number of images in a directory\n",
        "def count(directory):\n",
        "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n",
        "    image_count = sum(1 for filename in os.listdir(directory) if filename.lower().endswith(tuple(valid_extensions)))\n",
        "    return image_count\n",
        "\n",
        "# Segment images using k-means clustering\n",
        "def segment_images(image_direc,cluster_direc, images, k):\n",
        "    # Extract features from all images\n",
        "    features = [get_image_feature(img).cpu().numpy().flatten() for _, img in images]\n",
        "\n",
        "    # Perform k-means clustering\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0).fit(features)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Create directory for each cluster\n",
        "    for i in range(k):\n",
        "        os.makedirs(os.path.join(cluster_direc, f'cluster_{i}'), exist_ok=True)\n",
        "\n",
        "    # Save images to corresponding cluster directory\n",
        "    # for (filename, img), label in zip(images, labels):\n",
        "    #     img.save(os.path.join(image_direc, f'cluster_{label}', filename))\n",
        "    cluster_log = {i: [] for i in range(k)}\n",
        "    for (filename, img), label in zip(images, labels):\n",
        "        img.save(os.path.join(cluster_direc, f'cluster_{label}', filename))\n",
        "        cluster_log[label].append(filename)\n",
        "\n",
        "    return labels,cluster_log\n",
        "\n",
        "\n",
        "\n",
        "import shutil\n",
        "\n",
        "def clusters(cluster_log, image_direc, saliency_direc, output_direc):\n",
        "    # Iterate over each cluster and its associated filenames\n",
        "    for cluster, filenames in cluster_log.items():\n",
        "        # Create the cluster directory in the output directory if it doesn't exist\n",
        "        cluster_output_dir = os.path.join(output_direc, f'cluster_{cluster}')\n",
        "        os.makedirs(cluster_output_dir, exist_ok=True)\n",
        "\n",
        "        for filename in filenames:\n",
        "            # Construct the image path in the image directory\n",
        "            # img_path = os.path.join(image_direc, f'cluster_{cluster}', filename)\n",
        "            img_path = os.path.join(image_direc, filename)\n",
        "            # Open the image to ensure it exists and is accessible\n",
        "            try:\n",
        "                image = Image.open(img_path)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Image {filename} not found in {img_path}. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Determine the corresponding saliency map filename\n",
        "            base_filename = os.path.splitext(filename)[0]\n",
        "            saliency_filename = base_filename + '.png'\n",
        "            saliency_path = os.path.join(saliency_direc, saliency_filename)\n",
        "\n",
        "            # Check if the saliency map exists\n",
        "            if os.path.exists(saliency_path):\n",
        "                # Move or copy the saliency map to the corresponding cluster folder in the output directory\n",
        "                target_path = os.path.join(cluster_output_dir, saliency_filename)\n",
        "                shutil.copy(saliency_path, target_path)\n",
        "            else:\n",
        "                print(f\"Saliency map {saliency_filename} not found in {saliency_direc}. Skipping...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# clusters(cluster_log, 'path/to/image_directory', 'path/to/saliency_directory', 'path/to/output_directory')\n",
        "\n",
        "\n",
        "# Main function to execute the workflow\n",
        "def main(image_directory,cluster_direc, k):\n",
        "    images = load_images_from_directory(image_directory)\n",
        "    labels,cluster_log = segment_images(image_directory,cluster_direc, images, k)\n",
        "    return labels,cluster_log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JbMKvJWHnsqx"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import resize, to_pil_image\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from skimage.measure import label, regionprops\n",
        "from torchvision.transforms.functional import resize, to_pil_image\n",
        "\n",
        "def prepare_mask(image, target_length=1024):\n",
        "    target_size = get_preprocess_shape(image.shape[0], image.shape[1], target_length)\n",
        "    mask = np.array(resize(to_pil_image(image), target_size))\n",
        "\n",
        "    if len(mask.shape) == 2:\n",
        "        mask = mask[:, :, None]\n",
        "\n",
        "    input_mask = torch.as_tensor(mask)\n",
        "    input_mask = input_mask.permute(2, 0, 1).contiguous()[None, :, :, :]\n",
        "    input_mask = preprocess(input_mask)\n",
        "    return input_mask\n",
        "\n",
        "# def point_selection(mask_sim, topk=1):\n",
        "#     w, h = mask_sim.shape\n",
        "#     topk_xy = mask_sim.flatten(0).topk(topk)[1]\n",
        "#     topk_x = (topk_xy // h).unsqueeze(0)\n",
        "#     topk_y = (topk_xy - topk_x * h)\n",
        "#     topk_xy = torch.cat((topk_y, topk_x), dim=0).permute(1, 0)\n",
        "#     topk_label = np.array([1] * topk)\n",
        "#     topk_xy = topk_xy.cpu().numpy()\n",
        "#     last_xy = mask_sim.flatten(0).topk(topk, largest=False)[1]\n",
        "#     last_x = (last_xy // h).unsqueeze(0)\n",
        "#     last_y = (last_xy - last_x * h)\n",
        "#     last_xy = torch.cat((last_y, last_x), dim=0).permute(1, 0)\n",
        "#     last_label = np.array([0] * topk)\n",
        "#     last_xy = last_xy.cpu().numpy()\n",
        "#     return topk_xy, topk_label, last_xy, last_label\n",
        "\n",
        "\n",
        "def point_selection22(sim,original_image):\n",
        "    attention_similarity = sim.sigmoid_().unsqueeze(0)\n",
        "    threshold = 0.7\n",
        "    binary_mask = (attention_similarity > threshold).float()\n",
        "\n",
        "              # Ensure the mask is 2D\n",
        "    binary_mask_np = binary_mask.squeeze(0).cpu().numpy().astype(np.uint8)\n",
        "    # print(f\"binary_mask_np shape: {binary_mask_np.shape}, dtype: {binary_mask_np.dtype}\")\n",
        "\n",
        "      #Perform connected component analysis\n",
        "    labeled_mask, num_labels = label(binary_mask_np, return_num=True)\n",
        "    # print(f\"labeled_mask shape: {labeled_mask.shape}, dtype: {labeled_mask.dtype}, num_labels: {num_labels}\")\n",
        "\n",
        "    #Find the size of the largest connected component\n",
        "    max_region_area = max(region.area for region in regionprops(labeled_mask))\n",
        "    size_threshold = max_region_area * 0.1\n",
        "\n",
        "    #Filter connected components based on size and find centroids\n",
        "    final_mask = np.zeros_like(labeled_mask)\n",
        "    centroids = []\n",
        "    for region in regionprops(labeled_mask):\n",
        "        if region.area >= size_threshold:  # Only keep regions that are at least 10% the size of the largest region\n",
        "          centroids.append((region.centroid[0], region.centroid[1]))\n",
        "          for coords in region.coords:\n",
        "            final_mask[coords[0], coords[1]] = 1\n",
        "\n",
        "    if isinstance(original_image, Image.Image) and original_image.size:\n",
        "        # Resize final mask to original image size\n",
        "        original_size = original_image.size[::-1]  # PIL Image size is (width, height), so reverse\n",
        "        print(\"Original image size:\", original_image.size)\n",
        "        print(\"final_mask size:\", final_mask.size)\n",
        "        if original_size:\n",
        "          final_mask_2d = final_mask.reshape((64, 64))\n",
        "          final_mask_resized = cv2.resize(final_mask_2d, original_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # Convert centroids to original image scale\n",
        "          scale_factor_y = original_size[0] / final_mask.shape[0]\n",
        "          scale_factor_x = original_size[1] / final_mask.shape[1]\n",
        "          # centroids = [tuple(region.centroid) for region in regionprops(labeled_mask) if region.area >= size_threshold]\n",
        "          centroids = [(int(y * scale_factor_y), int(x * scale_factor_x)) for y, x in centroids]\n",
        "          print(\"Centroid  \", centroids)\n",
        "          topk_coords = np.array(centroids)[:len(centroids)]\n",
        "          bottomk_coords = np.array(centroids)[:0]\n",
        "\n",
        "          topk_labels = np.array([1] * len(centroids))\n",
        "          bottomk_labels = np.array([0] * 0)\n",
        "          print(\"Top K Coordinates: \", topk_coords)\n",
        "          print(\"Top K Labels: \", topk_labels)\n",
        "          print(\"Bottom K Coordinates: \", bottomk_coords)\n",
        "          print(\"Bottom K Labels: \", bottomk_labels)\n",
        "          return topk_coords, topk_labels, bottomk_coords, bottomk_labels\n",
        "        else:\n",
        "          print(\"Error: Original image has invalid size. Cannot resize mask.\")\n",
        "          return None, None, None, None  # Handle the error as needed\n",
        "\n",
        "    else:\n",
        "        print(\"Error: Invalid original image. Unable to resize mask.\")\n",
        "        return None, None, None, None # or handle the error appropriately\n",
        "\n",
        "def preprocess(x: torch.Tensor, pixel_mean=[123.675, 116.28, 103.53], pixel_std=[58.395, 57.12, 57.375], img_size=1024) -> torch.Tensor:\n",
        "    pixel_mean = torch.Tensor(pixel_mean).view(-1, 1, 1)\n",
        "    pixel_std = torch.Tensor(pixel_std).view(-1, 1, 1)\n",
        "    x = (x - pixel_mean) / pixel_std\n",
        "    h, w = x.shape[-2:]\n",
        "    padh = img_size - h\n",
        "    padw = img_size - w\n",
        "    x = F.pad(x, (0, padw, 0, padh))\n",
        "    return x\n",
        "\n",
        "def get_preprocess_shape(oldh: int, oldw: int, long_side_length: int) -> Tuple[int, int]:\n",
        "    scale = long_side_length * 1.0 / max(oldh, oldw)\n",
        "    newh, neww = oldh * scale, oldw * scale\n",
        "    neww = int(neww + 0.5)\n",
        "    newh = int(newh + 0.5)\n",
        "    return (newh, neww)\n",
        "\n",
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([255, 0, 0, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Importing the Segment Anything model for using its decoder after the point prompts are generated\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "SZoDCcfDdHhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !mkdir images\n",
        "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n",
        "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/groceries.jpg\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "Ce-B_cNFjGE5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Load the SAM model and build necesary fucntions"
      ],
      "metadata": {
        "id": "3u04bzead2c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "7WtBqFVFi1gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))"
      ],
      "metadata": {
        "id": "ImEjzY-sj9HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create few directories where our output would be stored."
      ],
      "metadata": {
        "id": "DiXpmm0CeHUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir  '/content/IMAGES_IN_CLUSTERS/14'\n",
        "!mkdir  '/content/OUT-PUT-MASK/14'\n",
        "!mkdir  '/content/SALIENCY_IN_CLUSTERS/14'\n"
      ],
      "metadata": {
        "id": "Gq-6M-T3fEml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dbd880-98fb-4be6-dd2c-1583175a5f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/OUT-PUT-MASK/14’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IKuDyLJaG69G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "# Directory setup\n",
        "image_direct = '/content/drive/MyDrive/SURGEIMAGEfolder/images/018 Agra Taj Mahal-Inde du Nord 2004-Mhln'\n",
        "saliency_direc = '/content/drive/MyDrive/TOTAL-SALIENCY/18'\n",
        "!mkdir -p '/content/SALIENCY_IN_CLUSTERS/18'\n",
        "saliency_map_cluster_direc = '/content/SALIENCY_IN_CLUSTERS/18'\n",
        "!mkdir -p '/content/IMAGES_IN_CLUSTERS/18'\n",
        "image_cluster_direc = '/content/IMAGES_IN_CLUSTERS/18'\n",
        "!mkdir -p '/content/drive/MyDrive/OUT-PUT-MASK(BB)/18'\n",
        "output_directory = '/content/drive/MyDrive/OUT-PUT-MASK(BB)/18'\n",
        "\n",
        "k = math.ceil(count(image_direct) / 10)  # Number of clusters\n",
        "\n",
        "labels, cluster_log = main(image_direct, image_cluster_direc, k)\n",
        "print(labels)\n",
        "clusters(cluster_log, image_direct, saliency_direc, saliency_map_cluster_direc)\n",
        "\n",
        "\n",
        "\n",
        "image_clusters = [d for d in os.listdir(image_cluster_direc) if os.path.isdir(os.path.join(image_cluster_direc, d))]\n",
        "# List all image cluster folders\n",
        "for image_cluster in image_clusters:\n",
        "    # Construct the corresponding saliency map cluster directory\n",
        "    saliency_map_cluster = os.path.join(saliency_map_cluster_direc, image_cluster)\n",
        "\n",
        "    # Check if the corresponding saliency map cluster folder exists\n",
        "    if os.path.isdir(saliency_map_cluster):\n",
        "        image_cluster_path = os.path.join(image_cluster_direc, image_cluster)\n",
        "\n",
        "        image_files = sorted([f for f in os.listdir(image_cluster_path) if f.endswith(\".jpg\") or f.endswith(\".png\")])\n",
        "        image_files = [os.path.join(image_cluster_path, f) for f in image_files]  # Include full path\n",
        "\n",
        "        mask_files = sorted([f for f in os.listdir(saliency_map_cluster) if f.endswith(\".jpg\") or f.endswith(\".png\")])\n",
        "        mask_files = [os.path.join(saliency_map_cluster, f) for f in mask_files]  # Include full path\n",
        "\n",
        "        for test_image_filename in image_files:\n",
        "            if test_image_filename.endswith(\".jpg\") or test_image_filename.endswith(\".png\"):\n",
        "                file_path = os.path.join(image_cluster_path, test_image_filename)\n",
        "                test_image = Image.open(file_path).convert(\"RGB\")\n",
        "\n",
        "                # Prepare test image\n",
        "                inputs = processor(images=test_image, return_tensors=\"pt\").to(device)\n",
        "                pixel_values = inputs.pixel_values\n",
        "                with torch.no_grad():\n",
        "                    test_feat = model.get_image_embeddings(pixel_values).squeeze()\n",
        "\n",
        "                num_channels, height, width = test_feat.shape\n",
        "                test_feat = test_feat / test_feat.norm(dim=0, keepdim=True)\n",
        "                test_feat_reshaped = test_feat.reshape(num_channels, height * width)\n",
        "\n",
        "                # Initialize a list to store similarity matrices\n",
        "                sims_list = []\n",
        "\n",
        "                # Iterate over reference images\n",
        "                for ref_image_filename, ref_mask_filename in zip(image_files, mask_files):\n",
        "                    ref_image_path = os.path.join(image_cluster_path, ref_image_filename)\n",
        "                    ref_mask_path = os.path.join(saliency_map_cluster, ref_mask_filename)\n",
        "\n",
        "                    # Load reference image and mask\n",
        "                    ref_image = Image.open(ref_image_path).convert(\"RGB\")\n",
        "                    ref_mask = cv2.imread(ref_mask_path)\n",
        "                    ref_mask = cv2.cvtColor(ref_mask, cv2.COLOR_BGR2RGB)\n",
        "                    np.unique(ref_mask)\n",
        "\n",
        "                    # Precompute reference image features and mask processing\n",
        "                    pixel_values = processor(images=ref_image, return_tensors=\"pt\").pixel_values\n",
        "                    with torch.no_grad():\n",
        "                        ref_feat = model.get_image_embeddings(pixel_values.to(device))\n",
        "                        ref_feat = ref_feat.squeeze().permute(1, 2, 0)\n",
        "\n",
        "                    ref_mask = prepare_mask(ref_mask)\n",
        "                    ref_mask = F.interpolate(ref_mask, size=ref_feat.shape[0:2], mode=\"bilinear\")\n",
        "                    ref_mask = ref_mask.squeeze()[0]\n",
        "                    target_feat = ref_feat[ref_mask > 0]\n",
        "                    target_embedding = target_feat.mean(0).unsqueeze(0)\n",
        "                    target_feat = target_embedding / target_embedding.norm(dim=-1, keepdim=True)\n",
        "                    target_embedding = target_embedding.unsqueeze(0)\n",
        "\n",
        "                    # Compute similarity\n",
        "                    sim = target_feat @ test_feat_reshaped\n",
        "                    sim = sim.reshape(1, 1, height, width)\n",
        "                    sim = F.interpolate(sim, scale_factor=4, mode=\"bilinear\")\n",
        "                    sim = processor.post_process_masks(sim.unsqueeze(1), original_sizes=inputs[\"original_sizes\"].tolist(), reshaped_input_sizes=inputs[\"reshaped_input_sizes\"].tolist(), binarize=False)\n",
        "                    sim = sim[0].squeeze()\n",
        "                    sims_list.append(sim)\n",
        "                    print(f\"Processing: Test Image: {test_image_filename}, Reference Image: {ref_image_filename}, Reference Mask: {ref_mask_filename}\")\n",
        "\n",
        "                # Compute the average similarity matrix\n",
        "                avg_sim = torch.mean(torch.stack(sims_list), dim=0)\n",
        "\n",
        "                if avg_sim.max() > 1.0:\n",
        "                    avg_sim = avg_sim / avg_sim.max()\n",
        "\n",
        "                sim = avg_sim\n",
        "                sim = (sim - sim.mean()) / torch.std(sim)\n",
        "                # sim = F.interpolate(sim.unsqueeze(0).unsqueeze(0), size=(height, width), mode=\"bilinear\")  # Adjusted size here\n",
        "                attention_similarity = sim.sigmoid_().unsqueeze(0)\n",
        "\n",
        "\n",
        "                threshold = 0.69\n",
        "                binary_mask = (attention_similarity > threshold).float()\n",
        "\n",
        "# Ensure the mask is 2D\n",
        "                binary_mask_np = binary_mask.squeeze().cpu().numpy().astype(np.uint8)\n",
        "                print(f\"binary_mask_np shape: {binary_mask_np.shape}, dtype: {binary_mask_np.dtype}\")\n",
        "\n",
        "# Perform connected component analysis\n",
        "                labeled_mask, num_labels = label(binary_mask_np, return_num=True)\n",
        "                print(f\"labeled_mask shape: {labeled_mask.shape}, dtype: {labeled_mask.dtype}, num_labels: {num_labels}\")\n",
        "\n",
        "# Find the size of the largest connected component\n",
        "                max_region_area = max(region.area for region in regionprops(labeled_mask))\n",
        "                size_threshold = max_region_area * 0.1\n",
        "\n",
        "# Filter connected components based on size and find centroids and bounding boxes\n",
        "                final_mask = np.zeros_like(labeled_mask)\n",
        "                centroids = []\n",
        "                bounding_boxes = []\n",
        "                for region in regionprops(labeled_mask):\n",
        "                    if region.area >= size_threshold:  # Only keep regions that are at least 10% the size of the largest region\n",
        "                        centroids.append(region.centroid)\n",
        "                        bounding_boxes.append(region.bbox)\n",
        "                        for coords in region.coords:\n",
        "                            final_mask[coords[0], coords[1]] = 1\n",
        "\n",
        "# Resize final mask to original image size\n",
        "                original_size = test_image.size[::-1]  # PIL Image size is (width, height), so reverse\n",
        "                final_mask_resized = cv2.resize(final_mask, original_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "# Convert centroids to original image scale\n",
        "                scale_factor_y = original_size[0] / final_mask.shape[0]\n",
        "                scale_factor_x = original_size[1] / final_mask.shape[1]\n",
        "                centroids_original_scale = [(int(y * scale_factor_y), int(x * scale_factor_x)) for y, x in centroids]\n",
        "\n",
        "# Print or save the centroids\n",
        "                topk_xy_i = np.array(centroids_original_scale)[:len(centroids_original_scale)]\n",
        "                topk_label_i = np.array([1] * len(centroids_original_scale))\n",
        "\n",
        "                topk_xy = np.concatenate([topk_xy_i], axis=0)\n",
        "                topk_label = np.concatenate([topk_label_i], axis=0)\n",
        "\n",
        "                print(topk_xy)\n",
        "\n",
        "# Convert bounding boxes to original image scale\n",
        "                bounding_boxes_original_scale = []\n",
        "                for bbox in bounding_boxes:\n",
        "                    min_row, min_col, max_row, max_col = bbox\n",
        "                    x1 = int(min_col * scale_factor_x)\n",
        "                    y1 = int(min_row * scale_factor_y)\n",
        "                    x2 = int(max_col * scale_factor_x)\n",
        "                    y2 = int(max_row * scale_factor_y)\n",
        "                    bounding_boxes_original_scale.append([x1, y1, x2, y2])\n",
        "\n",
        "# Convert bounding boxes to tensor\n",
        "                input_boxes = bounding_boxes_original_scale\n",
        "                input_boxes = torch.tensor(input_boxes, device=device)  # Add this line\n",
        "\n",
        "\n",
        "# Print the input boxes\n",
        "                print(input_boxes)\n",
        "\n",
        "# Prepare the input points and labels for the predictor\n",
        "                test_image_np = np.array(test_image)\n",
        "                predictor.set_image(test_image_np)\n",
        "\n",
        "                input_point = topk_xy_i\n",
        "                input_point = input_point[:, ::-1]\n",
        "                input_label = topk_label_i\n",
        "# Create a copy of input_point before converting to tensor\n",
        "                input_point_tensor = torch.tensor(input_point.copy(), device=device)\n",
        "\n",
        "\n",
        "                transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, test_image_np.shape[:2])\n",
        "\n",
        "                masks, _, _ = predictor.predict_torch(\n",
        "                point_coords=None,  # Use the tensor here\n",
        "                point_labels=None,\n",
        "                boxes=transformed_boxes,\n",
        "                multimask_output=False,\n",
        "                )\n",
        "\n",
        "                # masks, scores, logits = predictor.predict(\n",
        "                #     point_coords=input_point,\n",
        "                #     point_labels=input_label,\n",
        "                #     multimask_output=True,\n",
        "                # )\n",
        "\n",
        "                def show_points(coords, labels, ax, marker_size=375):\n",
        "                    pos_points = coords[labels==1]\n",
        "                    neg_points = coords[labels==0]\n",
        "                    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "                    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                fig, ax = plt.subplots(figsize=(10, 10))\n",
        "                ax.imshow(test_image)\n",
        "\n",
        "# Combine masks and display them\n",
        "                combined_mask = np.zeros(test_image_np.shape[:2], dtype=np.uint8)\n",
        "                for mask in masks:\n",
        "                  mask_np = mask.cpu().numpy().squeeze()\n",
        "                  combined_mask = np.maximum(combined_mask, mask_np)\n",
        "                  show_mask(mask_np, ax, random_color=True)\n",
        "\n",
        "# Display boxes\n",
        "                for box in input_boxes:\n",
        "                  show_box(box.cpu().numpy(), ax)\n",
        "\n",
        "# Remove axis\n",
        "\n",
        "\n",
        "# Save the figure with the masks and boxes\n",
        "                output_path = os.path.join(output_directory, os.path.basename(test_image_filename))\n",
        "                plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
        "                plt.close(fig)\n",
        "                print(f\"Saved visualization to: {output_path}\")\n",
        "\n",
        "# Convert the selected mask to a binary mask\n",
        "                binary_mask = combined_mask.astype(np.uint8)\n",
        "\n",
        "# Convert binary mask to PIL image\n",
        "                binary_mask_pil = Image.fromarray(binary_mask * 255)\n",
        "\n",
        "# Save the binary mask\n",
        "                binary_mask_output_path = os.path.join(output_directory, os.path.basename(test_image_filename).replace('.jpg', '.png'))\n",
        "                binary_mask_pil.save(binary_mask_output_path)\n",
        "                print(f\"Saved binary mask to: {binary_mask_output_path}\")\n",
        "\n",
        "# --------new above --------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # all_masks = []\n",
        "                # all_scores = []\n",
        "\n",
        "                # for points, labels, box in zip(points_sets, labels_sets, boxes):\n",
        "                #       masks, scores, _ = predictor.predict(point_coords=points, point_labels=labels, box=box)\n",
        "                #       all_masks.append(masks)\n",
        "                #       all_scores.append(scores)\n",
        "                # plt.figure(figsize=(10, 10))\n",
        "                # plt.imshow(test_image)\n",
        "                # show_mask(all_masks.cpu().numpy(), plt.gca(), random_color=True)\n",
        "\n",
        "\n",
        "#                 def show_points(coords, labels, ax, marker_size=375):\n",
        "#                     pos_points = coords[labels==1]\n",
        "#                     neg_points = coords[labels==0]\n",
        "#                     ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "#                     ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#                 plt.figure(figsize=(10, 10))\n",
        "#                 plt.imshow(test_image)\n",
        "#                 combined_mask = np.zeros(test_image_np.shape[:2], dtype=np.uint8)\n",
        "#                 for mask in masks:\n",
        "#                     mask_np = mask.cpu().numpy().squeeze()\n",
        "#                     combined_mask = np.maximum(combined_mask, mask_np)\n",
        "#                     show_mask(mask.cpu().numpy(), plt.gca(), random_color=True)\n",
        "#                 for box in input_boxes:\n",
        "#                     show_box(box.cpu().numpy(), plt.gca())\n",
        "#                 plt.axis('off')\n",
        "#                 plt.show()\n",
        "\n",
        "# # Convert the selected mask to a binary mask\n",
        "#                 binary_mask = combined_mask.astype(np.uint8)\n",
        "\n",
        "# # Convert binary mask to PIL image\n",
        "#                 binary_mask_pil = Image.fromarray(binary_mask * 255)\n",
        "\n",
        "# # Save the binary mask\n",
        "#                 output_path = os.path.join(output_directory, os.path.basename(test_image_filename))\n",
        "#                 binary_mask_pil.save(output_path)\n",
        "#                 print(f\"Saved mask to: {output_path}\")\n",
        "\n",
        "                # # Convert to binary mask\n",
        "                # binary_mask = (masks[2] > 0.5).astype(np.uint8)\n",
        "\n",
        "                # # Convert binary mask to PIL image\n",
        "                # binary_mask_pil = Image.fromarray(binary_mask * 255)\n",
        "\n",
        "                # # Create a draw object\n",
        "\n",
        "                # # Draw the points on the mask\n",
        "\n",
        "\n",
        "                # # Save the binary mask\n",
        "                # output_path = os.path.join(output_directory, os.path.basename(test_image_filename))\n",
        "                # binary_mask_pil.save(output_path)\n",
        "                # print(f\"Saved mask to: {output_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After the results is stored you can also check the iou score with its Ground Truth"
      ],
      "metadata": {
        "id": "F7E6P5NPewFS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pDmRwr-Xf0ZF"
      },
      "outputs": [],
      "source": [
        "#IOU SCORE.\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def calculate_iou(ground_truth, prediction):\n",
        "    # Convert binary masks to float (0.0 or 1.0)\n",
        "    gt = ground_truth.astype(np.float32)\n",
        "    pred = prediction.astype(np.float32)\n",
        "\n",
        "    if gt.shape != pred.shape:\n",
        "      pred = np.array(Image.fromarray(pred).resize(gt.shape[::-1], Image.NEAREST))\n",
        "\n",
        "    # Add both masks\n",
        "    combined = gt + pred\n",
        "\n",
        "    # Calculate number of 2's (intersection) and number of 1's (union - intersection)\n",
        "    intersection = np.sum(combined == 2)\n",
        "    union = np.sum(combined >= 1)\n",
        "\n",
        "    # Calculate IoU score\n",
        "    iou = intersection / union if union != 0 else 0\n",
        "    return iou\n",
        "\n",
        "def find_file_with_extension(directory, basename, extensions):\n",
        "    for ext in extensions:\n",
        "        filename = f\"{basename}{ext}\"\n",
        "        if os.path.isfile(os.path.join(directory, filename)):\n",
        "            return filename\n",
        "    return None\n",
        "\n",
        "def main2():\n",
        "    # Directories containing the ground truth and predicted masks\n",
        "    ground_truth_dir = \"/content/drive/MyDrive/ground_truth/040 Monks-LAO PDR 2008-Rolandito\"\n",
        "    predicted_dir = \"/content/drive/MyDrive/OUT-PUT-MASK/40\"\n",
        "    extensions = ['.jpg', '.png']\n",
        "\n",
        "    !mkdir = \"/content/drive/MyDrive/IOU-NEW\"\n",
        "    output_file = \"/content/drive/MyDrive/IOU-NEW/iou_scores_40.txt\"\n",
        "    # List of mask filenames (assuming filenames are the same in both directories)\n",
        "    ground_truth_files = [f for f in os.listdir(ground_truth_dir) if os.path.isfile(os.path.join(ground_truth_dir, f)) and (f.endswith('.jpg') or f.endswith('.png'))]\n",
        "    predicted_files = [f for f in os.listdir(predicted_dir) if os.path.isfile(os.path.join(predicted_dir, f)) and (f.endswith('.jpg') or f.endswith('.png'))]\n",
        "\n",
        "    ground_truth_basenames = {os.path.splitext(f)[0]: f for f in ground_truth_files}\n",
        "    predicted_basenames = {os.path.splitext(f)[0]: f for f in predicted_files}\n",
        "\n",
        "    # Check if both directories contain the same number of masks\n",
        "    assert len(ground_truth_files) == len(predicted_files), \"Mismatch in the number of masks between the two directories\"\n",
        "\n",
        "    # Initialize a list to store individual IoU scores\n",
        "    iou_scores = []\n",
        "\n",
        "    # Calculate IoU for each pair of masks\n",
        "    for basename, gt_filename in ground_truth_basenames.items():\n",
        "      pred_filename = find_file_with_extension(predicted_dir, basename, extensions)\n",
        "      if not pred_filename:\n",
        "            print(f\"Corresponding predicted file for {gt_filename} not found.\")\n",
        "            continue\n",
        "      gt_mask = np.array(Image.open(os.path.join(ground_truth_dir, gt_filename)).convert('L'))\n",
        "      pred_mask = np.array(Image.open(os.path.join(predicted_dir, pred_filename)).convert('L'))\n",
        "\n",
        "        # Convert to binary masks (assuming threshold at 128)\n",
        "      gt_mask = (gt_mask >= 128).astype(np.float32)\n",
        "      pred_mask = (pred_mask >= 128).astype(np.float32)\n",
        "\n",
        "        # Calculate IoU score\n",
        "      iou = calculate_iou(gt_mask, pred_mask)\n",
        "      iou_scores.append((basename, iou))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    average_iou = np.mean([score for _, score in iou_scores])\n",
        "\n",
        "    # Save individual IoU scores and final average to a text file\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        for filename, score in iou_scores:\n",
        "            f.write(f\"{filename}: {score:.4f}\\n\")\n",
        "        f.write(f\"\\nAverage IoU: {average_iou:.4f}\\n\")\n",
        "\n",
        "    print(f\"Individual IoU scores and average IoU saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTKyli8Pyyry"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def delete_non_empty_folder(folder_path):\n",
        "    if os.path.exists(folder_path):\n",
        "        if os.path.islink(folder_path):  # Check if it's a symbolic link\n",
        "            os.unlink(folder_path)  # Remove the symbolic link itself\n",
        "            print(f\"Deleted symbolic link: {folder_path}\")\n",
        "        elif os.path.isdir(folder_path):\n",
        "            shutil.rmtree(folder_path)  # Use rmtree for directories\n",
        "            print(f\"Deleted non-empty folder: {folder_path}\")\n",
        "        else:\n",
        "            print(f\"Path is not a folder or symbolic link: {folder_path}\")\n",
        "    else:\n",
        "        print(f\"Path does not exist: {folder_path}\")\n",
        "\n",
        "# Usage\n",
        "folder_to_delete = '/content/Output/50_2'\n",
        "delete_non_empty_folder(folder_to_delete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA4CPD82nDr3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def extract_average_iou(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        # The last line contains the average IoU\n",
        "        for line in lines:\n",
        "            if \"Average IoU\" in line:\n",
        "                avg_iou = float(line.split(\":\")[-1].strip())\n",
        "                return avg_iou\n",
        "    return None\n",
        "\n",
        "def main3():\n",
        "    # Directory containing the IoU score text files\n",
        "    iou_scores_dir = \"/content/drive/MyDrive/IOU_SCORE\"  # Replace with your directory path\n",
        "    iou_files = [f for f in os.listdir(iou_scores_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # List to store average IoU scores from each file\n",
        "    average_ious = []\n",
        "\n",
        "    for iou_file in iou_files:\n",
        "        iou_file_path = os.path.join(iou_scores_dir, iou_file)\n",
        "        avg_iou = extract_average_iou(iou_file_path)\n",
        "        if avg_iou is not None:\n",
        "            average_ious.append(avg_iou)\n",
        "\n",
        "    # Calculate the overall average IoU\n",
        "    if average_ious:\n",
        "        overall_average_iou = sum(average_ious) / len(average_ious)\n",
        "\n",
        "        output_file = \"final_iou_average.txt\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(f\"Overall Average IoU: {overall_average_iou:.4f}\\n\")\n",
        "            f.write(f\"Total number of IoU scores: {len(average_ious)}\\n\")\n",
        "\n",
        "        print(f\"Results saved to {output_file}\")\n",
        "        print(f\"Overall Average IoU: {overall_average_iou:.4f}\")\n",
        "    else:\n",
        "        print(\"No valid IoU scores found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main3()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOp9YeSopHT9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def extract_individual_ious(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        ious = []\n",
        "        for line in lines:\n",
        "            if \"Average IoU\" in line:\n",
        "                continue\n",
        "            if \":\" in line:\n",
        "                iou = float(line.split(\":\")[-1].strip())\n",
        "                ious.append(iou)\n",
        "    return ious\n",
        "\n",
        "def main4():\n",
        "    # Directory containing the IoU score text files\n",
        "    iou_scores_dir = \"/content/drive/MyDrive/IOU_SCORE\"  # Replace with your directory path\n",
        "    iou_files = [f for f in os.listdir(iou_scores_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # List to store individual IoU scores from each file\n",
        "    all_ious = []\n",
        "\n",
        "    for iou_file in iou_files:\n",
        "        iou_file_path = os.path.join(iou_scores_dir, iou_file)\n",
        "        ious = extract_individual_ious(iou_file_path)\n",
        "        if ious:\n",
        "            all_ious.extend(ious)\n",
        "\n",
        "    # Calculate the overall average IoU\n",
        "    if all_ious:\n",
        "        overall_average_iou = sum(all_ious) / len(all_ious)\n",
        "        print(f\"Overall Average IoU: {overall_average_iou:.4f}\")\n",
        "        print(f\"Total number of IoU scores: {len(all_ious)}\")\n",
        "\n",
        "        # Save the result to a text file\n",
        "        output_file = \"final_iou_average_per_image.txt\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(f\"Overall Average IoU: {overall_average_iou:.4f}\\n\")\n",
        "            f.write(f\"Total number of IoU scores: {len(all_ious)}\\n\")\n",
        "\n",
        "        print(f\"Results saved to {output_file}\")\n",
        "    else:\n",
        "        print(\"No valid IoU scores found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main4()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOjrNl3_sk7U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def extract_average_iou(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        # The last line contains the average IoU\n",
        "        for line in lines:\n",
        "            if \"Average IoU\" in line:\n",
        "                avg_iou = float(line.split(\":\")[-1].strip())\n",
        "                return avg_iou\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    # Directory containing the IoU score text files\n",
        "    iou_scores_dir = \"/content/drive/MyDrive/IOU_SCORE\"  # Replace with your directory path\n",
        "    iou_files = [f for f in os.listdir(iou_scores_dir) if f.endswith('.txt')]\n",
        "\n",
        "    # List to store average IoU scores from each file\n",
        "    average_ious = []\n",
        "    num_folders = 0\n",
        "    num_folders_above_09 = 0\n",
        "    num_folders_above_08 = 0\n",
        "    num_folders_above_07 = 0\n",
        "    num_folders_above_06 = 0\n",
        "\n",
        "    # Lists to store average IoU for folders with IoU > 0.9, 0.8, 0.7, and 0.6\n",
        "    avg_iou_above_09 = []\n",
        "    avg_iou_above_08 = []\n",
        "    avg_iou_above_07 = []\n",
        "    avg_iou_above_06 = []\n",
        "\n",
        "    for iou_file in iou_files:\n",
        "        iou_file_path = os.path.join(iou_scores_dir, iou_file)\n",
        "        avg_iou = extract_average_iou(iou_file_path)\n",
        "        if avg_iou is not None:\n",
        "            average_ious.append(avg_iou)\n",
        "            num_folders += 1\n",
        "            if avg_iou > 0.9:\n",
        "                num_folders_above_09 += 1\n",
        "                avg_iou_above_09.append(avg_iou)\n",
        "            if avg_iou > 0.8:\n",
        "                num_folders_above_08 += 1\n",
        "                avg_iou_above_08.append(avg_iou)\n",
        "            if avg_iou > 0.7:\n",
        "                num_folders_above_07 += 1\n",
        "                avg_iou_above_07.append(avg_iou)\n",
        "            if avg_iou > 0.6:\n",
        "                num_folders_above_06 += 1\n",
        "                avg_iou_above_06.append(avg_iou)\n",
        "\n",
        "    # Calculate the total average IoU\n",
        "    if average_ious:\n",
        "        total_average_iou = sum(average_ious) / len(average_ious)\n",
        "        # Calculate average IoU for folders with IoU > 0.9, 0.8, 0.7, and 0.6\n",
        "        avg_iou_09 = sum(avg_iou_above_09) / len(avg_iou_above_09) if avg_iou_above_09 else 0\n",
        "        avg_iou_08 = sum(avg_iou_above_08) / len(avg_iou_above_08) if avg_iou_above_08 else 0\n",
        "        avg_iou_07 = sum(avg_iou_above_07) / len(avg_iou_above_07) if avg_iou_above_07 else 0\n",
        "        avg_iou_06 = sum(avg_iou_above_06) / len(avg_iou_above_06) if avg_iou_above_06 else 0\n",
        "\n",
        "        # Save the result to a text file\n",
        "        output_file = \"folder_iou_statistics2.txt\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(f\"Total Average IoU: {total_average_iou:.4f}\\n\")\n",
        "            f.write(f\"Total number of folders: {num_folders}\\n\")\n",
        "            f.write(f\"Number of folders with IoU > 0.9: {num_folders_above_09}\\n\")\n",
        "            f.write(f\"Average IoU for folders with IoU > 0.9: {avg_iou_09:.4f}\\n\")\n",
        "            f.write(f\"Number of folders with IoU > 0.8: {num_folders_above_08}\\n\")\n",
        "            f.write(f\"Average IoU for folders with IoU > 0.8: {avg_iou_08:.4f}\\n\")\n",
        "            f.write(f\"Number of folders with IoU > 0.7: {num_folders_above_07}\\n\")\n",
        "            f.write(f\"Average IoU for folders with IoU > 0.7: {avg_iou_07:.4f}\\n\")\n",
        "            f.write(f\"Number of folders with IoU > 0.6: {num_folders_above_06}\\n\")\n",
        "            f.write(f\"Average IoU for folders with IoU > 0.6: {avg_iou_06:.4f}\\n\")\n",
        "\n",
        "        print(f\"Results saved to {output_file}\")\n",
        "    else:\n",
        "        print(\"No valid IoU scores found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}